# -*- coding: utf-8 -*-
"""paddleocr

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XFBohwxEKGe1Naz4wojBMmvjgWMjtagD

### Install
"""
#
# !pip install pdf2image
# !apt-get install poppler-utils
# !python3 -m pip install paddlepaddle-gpu
# !pip install layoutparser
# !pip install torchvision
# # !pip list --outdated
# !pip install protobuf== 3.20.0
# # !pip install Pillow
# !pip install "paddlepaddle>=2.0.1"
# !pip install paddleocr
#
# !git clone https://github.com/PaddlePaddle/PaddleOCR.git
#
# !pip install pillow==8.2.0
#
# !pip install pytesseract

from pdf2image import convert_from_path

import torch
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.transforms import functional as F
import numpy as np
import cv2
import pytesseract  # Instead of 'lp', use 'pytesseract'
import layoutparser as lp

# Load the image
image = cv2.imread("PNG.png")

# # Preprocess the image
# image_tensor = F.to_tensor(image)
# image_tensor = torch.unsqueeze(image_tensor, 0)
#
# # Load the pre-trained Faster R-CNN model
# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
# model.eval()
#
# # Perform inference
# with torch.no_grad():
#     predictions = model(image_tensor)
#
# # Threshold for detection confidence
# threshold = 0.5
#
# # Convert the predictions to Layout format
# # (Assuming that lp is the pytesseract layout processing library)
# import layoutparser as lp
#
# layout = lp.Layout()
#
# # Process each detected object
# # Update the label_map based on the actual indices predicted by the model
# label_map = {
#     0: "Background",  # Assuming 0 is the background class
#     1: "Text",
#     2: "Title",
#     3: "List",
#     4: "Table",
#     5: "Figure"
# }
#
# for i in range(len(predictions[0]['labels'])):
#     label = predictions[0]['labels'][i].item()
#     score = predictions[0]['scores'][i].item()
#     box = predictions[0]['boxes'][i].detach().numpy()
#
#     if score >= threshold:
#         # Check if the label exists in the label_map
#         if label in label_map:
#             label_name = label_map[label]
#         else:
#             label_name = "Unknown"
#
#         # Create a Rectangle object using the bounding box coordinates
#         x1, y1, x2, y2 = box
#         rectangle = lp.Rectangle(x1, y1, x2, y2)
#
#         # Create a TextBlock object with the Rectangle
#         text_block = lp.TextBlock(rectangle, type=label_name, score=score)
#
#         # Append the TextBlock object to the layout
#         layout.append(text_block)
#
# # Print the layout
# print(layout)
#
# text_elements = [element for element in layout if element.type == "list"]
#
# for element in text_elements:
#     x_1, y_1, x_2, y_2 = element.block.coordinates
#
#     # Use the coordinates as needed
#     # print(f"Bounding box coordinates: ({x_1}, {y_1}, {x_2}, {y_2})")
#     # Perform further processing with the coordinates
#
# for element in layout:
#     # if element.type == 'Table':
#         x_1 = int(element.block.x_1)
#         y_1 = int(element.block.y_1)
#         x_2 = int(element.block.x_2)
#         y_2 = int(element.block.y_2)
#         break
#
# # Extract the region of interest
# extracted_image = image[y_1:y_2, x_1:x_2]
#
# # Save the extracted image
# cv2.imwrite('ext_im.png', extracted_image)

image = image[..., ::-1]

# load model
model = lp.PaddleDetectionLayoutModel(config_path="lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config",
                                threshold=0.5,
                                label_map={0: "Text", 1: "Title", 2: "List", 3:"Table", 4:"Figure"},
                                enforce_cpu=False,
                                enable_mkldnn=True)#math kernel library
# detect
layout = model.detect(image)
x_1=0
y_1=0
x_2=0
y_2=0

for l in layout:
  #print(l)
  if l.type == 'Table':
    x_1 = int(l.block.x_1)
    print(l.block.x_1)
    y_1 = int(l.block.y_1)
    x_2 = int(l.block.x_2)
    y_2 = int(l.block.y_2)

    break
im = cv2.imread('PNG.png')
cv2.imwrite('ext_im.png', im[y_1:y_2,x_1:x_2])
"""### Text dectection and recognition"""

# !apt-get update
# !apt-get install -y libssl-dev
#
# !pip install paddleocr

from paddleocr import PaddleOCR

ocr = PaddleOCR(lang='en')

image_path ='ext_im.png'
image_cv = cv2.imread(image_path)
image_height = image_cv.shape[0]
image_width = image_cv.shape[1]
output = ocr.ocr(image_path)

boxes = [line[0] for line in output[0]]
text = [line[1][0] for line in output[0]]
probabilities = [line[1][1] for line in output[0]]

image_boxes = image_cv.copy()

for box in boxes:
  cv2.rectangle(image_boxes,(int(box[0][0]),int(box[0][1])), (int(box[2][0]),int(box[2][1])), (0,0,255),1 )

# from PIL import Image, ImageDraw, ImageFont

# ia = Image.open('/content/ext_im.jpg').convert('RGB')

# im_show = draw_ocr(ia, boxes, text, probabilities,font_path='/usr/share/fonts/truetype/humor-sans/Humor-Sans.ttf' )
# im_show = Image.fromarray(im_show)
# im_show.save('result.jpg')

"""### Recontruction"""

ima = image_cv.copy()

horiz_boxes = []
vert_boxes = []

for box in boxes:
  x_h, x_v = 0,int(box[0][0])
  y_h, y_v = int(box[0][1]),0

  width_h, width_v = image_width, int(box[2][0]-box[0][0])
  height_h, height_v = int(box[2][1]- box[0][1]), image_height

  horiz_boxes.append([x_h,y_h, x_h+ width_h, y_h + height_h])
  vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])

  cv2.rectangle(ima,(x_h,y_h),(x_h+ width_h, y_h + height_h), (0,0,255),1 )
  cv2.rectangle(ima,(x_v,y_v),(x_v+ width_v, y_v + height_v), (255,255,0),1 )

import tensorflow as tf
horiz_out = tf.image.non_max_suppression(
    horiz_boxes,               # Tensor of shape [num_boxes, 4] containing the bounding boxes
    probabilities,             # Tensor of shape [num_boxes] containing the corresponding probabilities
    max_output_size=1000,      # Maximum number of selected boxes
    iou_threshold=0.2,         # Intersection over union (IoU) threshold for overlapping boxes
    score_threshold=float('-inf'),  # Optional score threshold for discarding boxes
    name=None                  # Optional name for the operation
)

import numpy as np

horiz_line = np.sort(np.array(horiz_out))

im_nms = image_cv.copy()

for val in horiz_line:
    cv2.rectangle(im_nms,(int(horiz_boxes[val][0]),int(horiz_boxes[val][1])), (int(horiz_boxes[val][2]),int(horiz_boxes[val][3])), (0,0,255),1 )

import tensorflow as tf
vert_out = tf.image.non_max_suppression(
    vert_boxes,               # Tensor of shape [num_boxes, 4] containing the bounding boxes
    probabilities,             # Tensor of shape [num_boxes] containing the corresponding probabilities
    max_output_size=1000,      # Maximum number of selected boxes
    iou_threshold=0.1,         # Intersection over union (IoU) threshold for overlapping boxes
    score_threshold=float('-inf'),  # Optional score threshold for discarding boxes
    name=None                  # Optional name for the operation
)

vert_line = np.sort(np.array(vert_out))

for val in vert_line:
    cv2.rectangle(im_nms,(int(vert_boxes[val][0]),int(vert_boxes[val][1])), (int(vert_boxes[val][2]),int(vert_boxes[val][2])), (0,255,0),1 )

"""### Convert to CSV"""

out_array = [["" for i in range(len(vert_line))] for j in range(len(horiz_line))]

unordered_boxes = []

for i in vert_line:
  unordered_boxes.append(vert_boxes[i][0])

ordered_box = np.argsort(unordered_boxes)

def intersection(box_1, box_2):
  return [box_2[0],box_1[1], box_2[2], box_1[3]]

def iou(box_1, box_2):
  x_1 = max(box_1[0], box_2[0])
  y_1 = max(box_1[1], box_2[1])

  x_2 = min(box_1[2], box_2[2])
  y_2 = min(box_1[3], box_2[3])

  inter = abs(max((x_2 - x_1, 0)) * max((y_2- y_1),0))
  if inter == 0:
    return 0

  box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))
  box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))
  return inter / float(box_1_area + box_2_area - inter)

for i in range(len(horiz_line)):
  for j in range(len(vert_line)):
    resultant = intersection(horiz_boxes[horiz_line[i]], vert_boxes[vert_line[ordered_box[j]]])

    for b in range(len(boxes)):
      the_box = [boxes[b][0][0], boxes[b][0][1],boxes[b][2][0], boxes[b][2][1]]
      if (iou(resultant, the_box)> 0.1):
        out_array[i][j] = text[b]

import pandas as pd
pd.DataFrame(out_array).to_csv('PNG.csv')

